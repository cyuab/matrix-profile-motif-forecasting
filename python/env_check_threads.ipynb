{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c46241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Server Specs Detected ---\n",
      "Logical CPUs (Threads): 96\n",
      "Physical Cores:         48\n",
      "NUMA Nodes (Sockets):   2\n",
      "---------------------------\n",
      "Dataset Size: 20000\n",
      "✅ RECOMMENDED THREADS: 24\n",
      "Reason: Small dataset (<50k). Keeping purely on one CPU socket (Node) to avoid overhead.\n",
      "Numba threads set to: 24\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def get_cpu_specs():\n",
    "    \"\"\"Detects physical cores and NUMA nodes on Linux.\"\"\"\n",
    "    specs = {\n",
    "        \"logical_cpus\": os.cpu_count(),\n",
    "        \"physical_cores\": None,\n",
    "        \"numa_nodes\": 1\n",
    "    }\n",
    "\n",
    "    # 1. Try to get Physical Cores (skipping Hyper-Threading)\n",
    "    try:\n",
    "        import psutil\n",
    "        specs[\"physical_cores\"] = psutil.cpu_count(logical=False)\n",
    "    except ImportError:\n",
    "        # Fallback for Linux if psutil is not installed\n",
    "        try:\n",
    "            with open('/proc/cpuinfo') as f:\n",
    "                core_ids = set()\n",
    "                for line in f:\n",
    "                    if line.startswith('core id'):\n",
    "                        core_ids.add(line.strip().split(':')[1])\n",
    "                # This is a rough estimate; psutil is better\n",
    "                specs[\"physical_cores\"] = len(core_ids) * specs[\"numa_nodes\"]\n",
    "        except:\n",
    "            specs[\"physical_cores\"] = specs[\"logical_cpus\"] // 2  # Safe guess\n",
    "\n",
    "    # 2. Detect NUMA Nodes (Sockets)\n",
    "    # This checks how many CPU chips you have (likely 2 on a server)\n",
    "    try:\n",
    "        nodes = [d for d in os.listdir('/sys/devices/system/node') if d.startswith('node')]\n",
    "        specs[\"numa_nodes\"] = len(nodes)\n",
    "    except:\n",
    "        specs[\"numa_nodes\"] = 1\n",
    "\n",
    "    return specs\n",
    "\n",
    "def recommend_threads(dataset_size_n):\n",
    "    specs = get_cpu_specs()\n",
    "    phy_cores = specs[\"physical_cores\"]\n",
    "    nodes = specs[\"numa_nodes\"]\n",
    "    \n",
    "    print(f\"--- Server Specs Detected ---\")\n",
    "    print(f\"Logical CPUs (Threads): {specs['logical_cpus']}\")\n",
    "    print(f\"Physical Cores:         {phy_cores}\")\n",
    "    print(f\"NUMA Nodes (Sockets):   {nodes}\")\n",
    "    print(f\"---------------------------\")\n",
    "\n",
    "    # LOGIC for Stumpy/Numba\n",
    "    recommendation = 0\n",
    "    reason = \"\"\n",
    "\n",
    "    if dataset_size_n < 50_000:\n",
    "        # Rule: Small data -> Stay on ONE CPU socket to avoid slow RAM transfer\n",
    "        recommendation = phy_cores // nodes\n",
    "        reason = f\"Small dataset (<50k). Keeping purely on one CPU socket (Node) to avoid overhead.\"\n",
    "    else:\n",
    "        # Rule: Large data -> Use all PHYSICAL cores\n",
    "        recommendation = phy_cores\n",
    "        reason = \"Large dataset. Using all physical cores (avoiding Hyper-Threading).\"\n",
    "\n",
    "    print(f\"Dataset Size: {dataset_size_n}\")\n",
    "    print(f\"✅ RECOMMENDED THREADS: {recommendation}\")\n",
    "    print(f\"Reason: {reason}\")\n",
    "    \n",
    "    return recommendation\n",
    "\n",
    "# --- USAGE EXAMPLE ---\n",
    "# Change this number to your actual data size\n",
    "best_threads = recommend_threads(dataset_size_n=20_000)\n",
    "\n",
    "# Apply it immediately\n",
    "from numba import set_num_threads\n",
    "set_num_threads(best_threads)\n",
    "print(f\"Numba threads set to: {best_threads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e3a23fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using GPU\n",
    "import os\n",
    "# Must be set before importing libraries that use the GPU!\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\" # Example: Only expose the RTX 5880 (Index 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "061b0cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Threads Time: 0.7755 seconds\n",
      "48 Threads Time: 0.9439 seconds\n"
     ]
    }
   ],
   "source": [
    "import stumpy\n",
    "import numpy as np\n",
    "import time\n",
    "from numba import set_num_threads\n",
    "\n",
    "# Generate dummy data similar to yours\n",
    "data = np.random.rand(20000)\n",
    "m = 50  # Window size\n",
    "\n",
    "stumpy.stump(data, m)\n",
    "# Test 1: The Recommendation (Single Socket)\n",
    "set_num_threads(8)\n",
    "start = time.time()\n",
    "stumpy.stump(data, m)\n",
    "print(f\"24 Threads Time: {time.time() - start:.4f} seconds\")\n",
    "\n",
    "# Test 2: The \"More is Better\" Trap (Cross-Socket)\n",
    "set_num_threads(48)\n",
    "start = time.time()\n",
    "stumpy.stump(data, m)\n",
    "print(f\"48 Threads Time: {time.time() - start:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stumpy_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
