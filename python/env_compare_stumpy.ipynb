{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add3e44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random time series of length 26,136...\n",
      "----------------------------------------\n",
      "Running CPU stumpy.stump() ...\n",
      "CPU Time: 15.3611 seconds\n",
      "----------------------------------------\n",
      "Warming up GPU (compiling kernels)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csproject/kdd/cyuab2/miniconda3/envs/stumpy_gpu/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 2 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GPU stumpy.gpu_stump() on Device 6...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/csproject/kdd/cyuab2/miniconda3/envs/stumpy_gpu/lib/python3.10/site-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 52 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Time: 4.2215 seconds\n",
      "----------------------------------------\n",
      "Summary for N=26,136:\n",
      "CPU: 15.3611s\n",
      "GPU: 4.2215s\n",
      "Speedup: 3.64x faster\n",
      "Results match: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import stumpy\n",
    "from numba import cuda\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# 1. Ensure Python ID matches nvidia-smi ID\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "# 2. Select your powerful GPU (Use 6 for your RTX 5880 Ada, or 0/1 for others)\n",
    "DEVICE_ID = 6\n",
    "\n",
    "# 3. Data Size\n",
    "# 10,000 = Instant on both\n",
    "# 50,000 = CPU takes ~10-20s, GPU is instant\n",
    "# 100,000 = CPU takes minutes, GPU takes seconds (Massive difference)\n",
    "N = 26_136 \n",
    "m = 24       # Window size\n",
    "\n",
    "# --- BENCHMARK SCRIPT ---\n",
    "\n",
    "def run_benchmark():\n",
    "    # Check if GPU is actually available to Numba\n",
    "    if not cuda.is_available():\n",
    "        print(\"Error: CUDA not available. Check your installation.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Generating random time series of length {N:,}...\")\n",
    "    T = np.random.rand(N)\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 1. CPU Benchmark\n",
    "    print(\"Running CPU stumpy.stump() ...\")\n",
    "    start_cpu = time.perf_counter()\n",
    "    mp_cpu = stumpy.stump(T, m)\n",
    "    end_cpu = time.perf_counter()\n",
    "    cpu_time = end_cpu - start_cpu\n",
    "    print(f\"CPU Time: {cpu_time:.4f} seconds\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # 2. GPU Warm-up (Compiles the CUDA kernel)\n",
    "    print(\"Warming up GPU (compiling kernels)...\")\n",
    "    stumpy.gpu_stump(np.random.rand(1000), m, device_id=DEVICE_ID)\n",
    "    \n",
    "    # 3. GPU Benchmark\n",
    "    print(f\"Running GPU stumpy.gpu_stump() on Device {DEVICE_ID}...\")\n",
    "    start_gpu = time.perf_counter()\n",
    "    mp_gpu = stumpy.gpu_stump(T, m, device_id=DEVICE_ID)\n",
    "    end_gpu = time.perf_counter()\n",
    "    gpu_time = end_gpu - start_gpu\n",
    "    print(f\"GPU Time: {gpu_time:.4f} seconds\")\n",
    "\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 4. Results\n",
    "    speedup = cpu_time / gpu_time\n",
    "    print(f\"Summary for N={N:,}:\")\n",
    "    print(f\"CPU: {cpu_time:.4f}s\")\n",
    "    print(f\"GPU: {gpu_time:.4f}s\")\n",
    "    print(f\"Speedup: {speedup:.2f}x faster\")\n",
    "\n",
    "    # 5. Verify Accuracy (sanity check)\n",
    "    # We compare the first column (Matrix Profile distances)\n",
    "    # Floating point math differences on GPU are normal, so we use allclose\n",
    "    is_close = np.allclose(mp_cpu[:, 0].astype(float), mp_gpu[:, 0].astype(float), atol=1e-5)\n",
    "    print(f\"Results match: {is_close}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_benchmark()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stumpy_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
