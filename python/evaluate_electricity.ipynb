{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acfd869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"XGBoostWB_Electricity\n",
    "\"\"\"\n",
    "import sys\n",
    "#Import Libraries\n",
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "import random\n",
    "# %matplotlib inline\n",
    "import shutil\n",
    "from random import shuffle\n",
    "import itertools\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "num_periods_output = 24 #to predict\n",
    "num_periods_input=24 #input\n",
    "\n",
    "ALL_Test_Data=[]\n",
    "ALL_Test_Prediction=[]\n",
    "\n",
    "\n",
    "\"\"\"## preprocessing\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def New_preprocessing(TimeSeries):\n",
    "   Data=[]\n",
    "   start_date=datetime(2012, 1, 1,00,00,00) # define start date\n",
    "   for i in range(0,len(TimeSeries)):\n",
    "      record=[]\n",
    "      record.append(TimeSeries[i])#adding the electricity value\n",
    "      record.append(start_date.month)\n",
    "      record.append(start_date.day)\n",
    "      record.append(start_date.hour)\n",
    "      record.append(start_date.weekday())\n",
    "      record.append(start_date.timetuple().tm_yday)\n",
    "      record.append(start_date.isocalendar()[1])\n",
    "      #print(start_date.month,' ',start_date.day,' ',start_date.hour,' ',start_date.weekday(),' ',start_date.timetuple().tm_yday,' ',start_date.isocalendar()[1])\n",
    "      start_date=start_date+ timedelta(hours=1)\n",
    "      #print('year',start_date.year,'Month:',start_date.month,' day:',start_date.day,' hour:',start_date.hour)\n",
    "      Data.append(record)\n",
    "   ########## change list of lists to df ################\n",
    "   headers=['electricity','month','day','hour','day_of_week','day_of_year','week_of_year']\n",
    "   Data_df = pd.DataFrame(Data, columns=headers)\n",
    "   #print(Data_df)\n",
    "   sub=Data_df.iloc[:,1:]\n",
    "   #Normalize features to be from -0.5 to 0.5 as mentioned in the paper\n",
    "   New_sub= preprocessing.minmax_scale(sub, feature_range=(-0.5, 0.5))\n",
    "   Normalized_Data_df=pd.DataFrame(pd.np.column_stack([Data_df.iloc[:,0],New_sub]), columns=headers)\n",
    "   #################################################################################################\n",
    "   # cut training and testing training is 25968\n",
    "   Train=Normalized_Data_df.iloc[0:25968,:]\n",
    "   Train=Train.values\n",
    "   Train = Train.astype('float32')\n",
    "   print('Traing length :',len(Train))\n",
    "   Test=Normalized_Data_df.iloc[(25968-num_periods_input):,:]\n",
    "   Test=Test.values\n",
    "   Test = Test.astype('float32')\n",
    "   print('Test length :',len(Test))\n",
    "   Number_Of_Features=7\n",
    "   ############################################ Windowing ##################################\n",
    "   end=len(Train)\n",
    "   start=0\n",
    "   next=0\n",
    "   x_batches=[]\n",
    "   y_batches=[]  \n",
    "   count=0\n",
    "   while next+(num_periods_input)<end:\n",
    "        next=start+num_periods_input\n",
    "        x_batches.append(Train[start:next,:])\n",
    "        y_batches.append(Train[next:next+num_periods_output,0])\n",
    "        start=start+1\n",
    "   y_batches=np.asarray(y_batches)\n",
    "   y_batches = y_batches.reshape(-1, num_periods_output, 1) \n",
    "   #print('Length of y batches :',len(y_batches),' ',num_periods_input,' ',num_periods_output)\n",
    "   #print(x_batches)\n",
    "   x_batches=np.asarray(x_batches) \n",
    "   x_batches = x_batches.reshape(-1, num_periods_input, Number_Of_Features)   \n",
    "   #print('len x_batches ',len(x_batches))\n",
    "   ############################################ Windowing ##################################\n",
    "   end_test=len(Test)\n",
    "   start_test=0\n",
    "   next_test=0\n",
    "   x_testbatches=[]\n",
    "   y_testbatches=[]\n",
    "   while next_test+(num_periods_input)<end_test:\n",
    "        next_test=start_test+num_periods_input\n",
    "        x_testbatches.append(Test[start_test:next_test,:])\n",
    "        y_testbatches.append(Test[next_test:next_test+num_periods_output,0])\n",
    "        start_test=start_test+num_periods_input\n",
    "   y_testbatches=np.asarray(y_testbatches)\n",
    "   y_testbatches = y_testbatches.reshape(-1, num_periods_output, 1)   \n",
    "   x_testbatches=np.asarray(x_testbatches)\n",
    "   x_testbatches = x_testbatches.reshape(-1, num_periods_input, Number_Of_Features) \n",
    "   #print('len Test',len(Test))\n",
    "   #print('len xTestbatches',len(x_testbatches))\n",
    "   return x_batches, y_batches, x_testbatches, y_testbatches\n",
    "\n",
    "data_path=r'/GBRT-for-TSF/Data/Univariate/electricity.npy'\n",
    "data=np.load(data_path)\n",
    "data= data[0:70,:]\n",
    "data=pd.DataFrame(data)\n",
    "###################################################\n",
    "x_batches_Full=[]\n",
    "y_batches_Full=[]\n",
    "X_Test_Full=[]\n",
    "Y_Test_Full=[]\n",
    "###################################################\n",
    "for i in range(0,len(data)):\n",
    "    x_batches=[]\n",
    "    y_batches=[]\n",
    "    X_Test=[]\n",
    "    Y_Test=[]\n",
    "    TimeSeries=data.iloc[i,:]\n",
    "    x_batches, y_batches,X_Test,Y_Test=New_preprocessing(TimeSeries)          \n",
    "    for element1 in (x_batches):\n",
    "        x_batches_Full.append(element1)\n",
    "        \n",
    "    for element2 in (y_batches):\n",
    "        y_batches_Full.append(element2)\n",
    "                    \n",
    "    for element5 in (X_Test):\n",
    "        X_Test_Full.append(element5)\n",
    "        \n",
    "    for element6 in (Y_Test):\n",
    "        Y_Test_Full.append(element6)\n",
    "\t\t\n",
    "#---------------------shuffle windows  X and target Y together-------------------------------------\n",
    "combined = list(zip(x_batches_Full, y_batches_Full))\n",
    "random.shuffle(combined)\n",
    "shuffled_batch_features, shuffled_batch_y = zip(*combined)\n",
    "\n",
    "#xgboost part\n",
    "All_Training_Instances=[]\n",
    " \n",
    "#=============== flatten each training window into Instance =================================\n",
    "for i in range(0,len(shuffled_batch_features)):\n",
    "    hold=[]\n",
    "    temp=[]\n",
    "    for j in range(0,len(shuffled_batch_features[i])):\n",
    "    #**************** to run without features -->comment if else condition (just keep else statement) **************************\n",
    "      if j==(len(shuffled_batch_features[i])-1):\n",
    "          hold=np.concatenate((hold, shuffled_batch_features[i][j][:]), axis=None)\n",
    "          \n",
    "      else:\n",
    "          hold=np.concatenate((hold, shuffled_batch_features[i][j][0]), axis=None)\n",
    "          \n",
    "    All_Training_Instances.append(hold)\n",
    "    \n",
    "\n",
    "print(len(All_Training_Instances[0]))\n",
    "\n",
    "#=============== flatten each testing window into Instance =================================\n",
    "All_Testing_Instances=[]\n",
    "for i in range(0,len(X_Test_Full)):\n",
    "  hold=[]\n",
    "  temp=[]\n",
    "  for j in range(0,len(X_Test_Full[i])):\n",
    "  #**************** to run without features -->comment if else condition (just keep else statement) **************************\n",
    "      if j==(len(X_Test_Full[i])-1):\n",
    "          hold=np.concatenate((hold, X_Test_Full[i][j][:]), axis=None)\n",
    "      else:\n",
    "          hold=np.concatenate((hold, X_Test_Full[i][j][0]), axis=None)\n",
    "   \n",
    "  All_Testing_Instances.append(hold)\n",
    "\n",
    "print(len(All_Testing_Instances[0]))\n",
    "\n",
    "#=========================== final shape check =========================\n",
    "All_Testing_Instances=np.reshape(All_Testing_Instances, (len(All_Testing_Instances),len(All_Testing_Instances[0])))\n",
    "Y_Test_Full=np.reshape(Y_Test_Full, (len(Y_Test_Full),num_periods_output))\n",
    "\n",
    "All_Training_Instances=np.reshape(All_Training_Instances, (len(All_Training_Instances),len(All_Training_Instances[0])))\n",
    "shuffled_batch_y=np.reshape(shuffled_batch_y, (len(shuffled_batch_y),num_periods_output))\n",
    "\n",
    "\n",
    "#=========================== CALLING XGBOOST ===========================\n",
    "model=xgb.XGBRegressor(learning_rate =0.2,\n",
    " n_estimators=150,\n",
    " max_depth=8,\n",
    " min_child_weight=1,\n",
    " gamma=0.0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " scale_pos_weight=1,\n",
    " seed=42,silent=False)\n",
    "\n",
    "multioutput=MultiOutputRegressor(model).fit(All_Training_Instances,shuffled_batch_y)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    a=(y_true - y_pred)\n",
    "    b=y_true\n",
    "    c=np.divide(a, b, out=np.zeros_like(a), where=b!=0)\n",
    "    return np.mean(np.abs(c)) * 100\n",
    "\n",
    "print('Fitting Done!')\n",
    "\n",
    "#============================== PREDICTION ===============================\n",
    "prediction=multioutput.predict(All_Testing_Instances)\n",
    "#print('prediction ',prediction.shape)\n",
    "#print('test ',Y_Test_Full.shape)\n",
    "MSE=np.mean((prediction- Y_Test_Full)**2)\n",
    "MAE=np.mean(np.abs((prediction- Y_Test_Full)))\n",
    "MAPE=mean_absolute_percentage_error(Y_Test_Full,prediction)\n",
    "WAPE=np.sum(np.abs(prediction- Y_Test_Full))/np.sum(np.abs(Y_Test_Full))\n",
    "#print('With Features for {} weeks'.format(No_Of_weeks)) \n",
    "print('MAPE: ',MAPE)\n",
    "print('WAPE: ',WAPE)\n",
    "print('MAE: ',MAE)\n",
    "#print('With Features for {} weeks'.format(No_Of_weeks)) \n",
    "print('RMSE: ',MSE**0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f59d055",
   "metadata": {},
   "source": [
    "# References\n",
    "1. [GBRT-for-TSF/XGBoost_(W-b)/Univariate/xgboostWB_electricity.py at main Â· Daniela-Shereen/GBRT-for-TSF](https://github.com/Daniela-Shereen/GBRT-for-TSF/blob/main/XGBoost_(W-b)/Univariate/xgboostWB_electricity.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e39f4",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(f\"This notebook was last run end-to-end on: {datetime.datetime.now()}\\n\")\n",
    "###\n",
    "###\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpmf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
