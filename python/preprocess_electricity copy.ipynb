{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e0c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"XGBoostWB_Electricity\n",
    "\"\"\"\n",
    "import sys\n",
    "#Import Libraries\n",
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "import random\n",
    "# %matplotlib inline\n",
    "import shutil\n",
    "from random import shuffle\n",
    "random.seed(42) \n",
    "import itertools\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from mpmf.utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c953f08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, world!\n"
     ]
    }
   ],
   "source": [
    "print_hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "784cfaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_features = True\n",
    "include_motif_information = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa7e9d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"electricity.npy\"\n",
    "data_path = r\"../data/\" + file_name\n",
    "data = np.load(data_path)\n",
    "data = data[0:1, :]\n",
    "# data= data[0:10,:]\n",
    "data = pd.DataFrame(data)\n",
    "###################################################\n",
    "num_periods_output = 24  # to predict\n",
    "num_periods_input = 24  # input\n",
    "\n",
    "\n",
    "m = num_periods_output - 1\n",
    "l = 1  # the next l points after the motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6f4fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_Test_Data = []\n",
    "ALL_Test_Prediction = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b93407",
   "metadata": {},
   "source": [
    "# Processing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952e0c7",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5143acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## preprocessing\"\"\"\n",
    "\n",
    "\n",
    "def New_preprocessing(TimeSeries):\n",
    "    Data = []\n",
    "    start_date = datetime(2012, 1, 1, 00, 00, 00)  # define start date\n",
    "    for i in range(0, len(TimeSeries)):\n",
    "        record = []\n",
    "        record.append(TimeSeries[i])  # adding the electricity value\n",
    "        record.append(start_date.month)\n",
    "        record.append(start_date.day)\n",
    "        record.append(start_date.hour)\n",
    "        record.append(start_date.weekday())\n",
    "        record.append(start_date.timetuple().tm_yday)\n",
    "        record.append(start_date.isocalendar()[1])\n",
    "\n",
    "        # Hide\n",
    "        # record.append(np.nan)\n",
    "        # record.append(np.nan)\n",
    "        # record.append(np.nan)\n",
    "        # record.append(np.nan)\n",
    "        # record.append(np.nan)\n",
    "        # record.append(np.nan)\n",
    "\n",
    "        # Append Motif information\n",
    "        # if include_motif_information:\n",
    "        #     record.extend(df_motif.iloc[i].tolist())\n",
    "        start_date = start_date + timedelta(hours=1)\n",
    "        Data.append(record)\n",
    "    ########## change list of lists to df ################\n",
    "    headers = [\n",
    "        \"electricity\",\n",
    "        \"month\",\n",
    "        \"day\",\n",
    "        \"hour\",\n",
    "        \"day_of_week\",\n",
    "        \"day_of_year\",\n",
    "        \"week_of_year\",\n",
    "    ]\n",
    "    # if include_features and include_motif_information:\n",
    "    #     headers=['electricity','month','day','hour','day_of_week','day_of_year','week_of_year'] + df_motif.columns.tolist()\n",
    "    # elif include_features and (not include_motif_information):\n",
    "    #     headers=['electricity','month','day','hour','day_of_week','day_of_year','week_of_year']\n",
    "    # elif (not include_features) and include_motif_information:\n",
    "    #     headers=['electricity'] + df_motif.columns.tolist()\n",
    "    # else:\n",
    "    #    #  headers=['electricity','month','day','hour','day_of_week','day_of_year','week_of_year'] # default\n",
    "    #     headers=['electricity']\n",
    "    Data_df = pd.DataFrame(Data, columns=headers)\n",
    "    # print(Data_df)\n",
    "    sub = Data_df.iloc[:, 1:]\n",
    "    # Normalize features to be from -0.5 to 0.5 as mentioned in the paper\n",
    "    New_sub = preprocessing.minmax_scale(sub, feature_range=(-0.5, 0.5))\n",
    "    Normalized_Data_df = pd.DataFrame(\n",
    "        np.column_stack([Data_df.iloc[:, 0], New_sub]), columns=headers\n",
    "    )\n",
    "\n",
    "    if include_motif_information:\n",
    "        df_motif = get_top_1_motif(TimeSeries, m, l, True)\n",
    "        Normalized_Data_df = pd.concat([Normalized_Data_df, df_motif], axis=1)\n",
    "\n",
    "    # if include_features and include_motif_information:\n",
    "    #     pass\n",
    "    # elif include_features and (not include_motif_information):\n",
    "    #     Normalized_Data_df = Normalized_Data_df.iloc[:, :len(headers)]\n",
    "    # elif (not include_features) and include_motif_information:\n",
    "    #     Normalized_Data_df = Normalized_Data_df.iloc[:, [0] + df_motif.columns.tolist()]\n",
    "    # else:\n",
    "    #     pass\n",
    "\n",
    "    #################################################################################################\n",
    "    # cut training and testing training is 25968\n",
    "    Train = Normalized_Data_df.iloc[0:25968, :]\n",
    "    Train = Train.values\n",
    "    Train = Train.astype(\"float32\")\n",
    "    #    print('Training length :',len(Train))\n",
    "    Test = Normalized_Data_df.iloc[(25968 - num_periods_input) :, :]\n",
    "    Test = Test.values\n",
    "    Test = Test.astype(\"float32\")\n",
    "    #    print('Test length :',len(Test))\n",
    "    # Number_Of_Features=7\n",
    "    Number_Of_Features = len(Normalized_Data_df.columns)\n",
    "    ############################################ Windowing ##################################\n",
    "    end = len(Train)\n",
    "    start = 0\n",
    "    next = 0\n",
    "    x_batches = []\n",
    "    y_batches = []\n",
    "    count = 0\n",
    "    while next + (num_periods_input) < end:\n",
    "        next = start + num_periods_input\n",
    "        x_batches.append(Train[start:next, :])\n",
    "        y_batches.append(Train[next : next + num_periods_output, 0])\n",
    "        start = start + 1\n",
    "    y_batches = np.asarray(y_batches)\n",
    "    y_batches = y_batches.reshape(-1, num_periods_output, 1)\n",
    "    # print('Length of y batches :',len(y_batches),' ',num_periods_input,' ',num_periods_output)\n",
    "    # print(x_batches)\n",
    "    x_batches = np.asarray(x_batches)\n",
    "    x_batches = x_batches.reshape(-1, num_periods_input, Number_Of_Features)\n",
    "    # print('len x_batches ',len(x_batches))\n",
    "    ############################################ Windowing ##################################\n",
    "    end_test = len(Test)\n",
    "    start_test = 0\n",
    "    next_test = 0\n",
    "    x_testbatches = []\n",
    "    y_testbatches = []\n",
    "    while next_test + (num_periods_input) < end_test:\n",
    "        next_test = start_test + num_periods_input\n",
    "        x_testbatches.append(Test[start_test:next_test, :])\n",
    "        y_testbatches.append(Test[next_test : next_test + num_periods_output, 0])\n",
    "        start_test = start_test + num_periods_input\n",
    "    y_testbatches = np.asarray(y_testbatches)\n",
    "    y_testbatches = y_testbatches.reshape(-1, num_periods_output, 1)\n",
    "    x_testbatches = np.asarray(x_testbatches)\n",
    "    x_testbatches = x_testbatches.reshape(-1, num_periods_input, Number_Of_Features)\n",
    "    # print('len Test',len(Test))\n",
    "    # print('len xTestbatches',len(x_testbatches))\n",
    "    # interested_cols = np.r_[0, -4:]\n",
    "    # x_batches = x_batches[:, :, [0, -1]]\n",
    "    x_batches = x_batches[:, :, :]\n",
    "    x_testbatches = x_testbatches[:, :, :]\n",
    "    # x_testbatches = x_testbatches[:, :, [0, -1]]\n",
    "    print(\"len x_batches\", x_batches.shape, \" len y_batches\", y_batches.shape)\n",
    "    print(\n",
    "        \"len x_testbatches\",\n",
    "        x_testbatches.shape,\n",
    "        \" len y_testbatches\",\n",
    "        y_testbatches.shape,\n",
    "    )\n",
    "    return x_batches, y_batches, x_testbatches, y_testbatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29afe4",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1951f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeries=data.iloc[0,:]\n",
    "# T = TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22748b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_batches, y_batches, x_testbatches, y_testbatches = New_preprocessing(TimeSeries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a0c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_testbatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f6050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_motif = get_motif_information(TimeSeries, m, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0e62b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data=[]\n",
    "# start_date=datetime(2012, 1, 1,00,00,00) # define start date\n",
    "# for i in range(0,len(TimeSeries)):\n",
    "#     record=[]\n",
    "#     record.append(TimeSeries[i])#adding the electricity value\n",
    "#     record.append(start_date.month)\n",
    "#     # print(start_date.month)\n",
    "#     record.append(start_date.day)\n",
    "#     record.append(start_date.hour)\n",
    "#     record.append(start_date.weekday())\n",
    "#     # print(start_date.weekday())\n",
    "#     record.append(start_date.timetuple().tm_yday)\n",
    "#     record.append(start_date.isocalendar()[1])\n",
    "#     # append all motif columns (no matter how many)\n",
    "#     record.extend(df_motif.iloc[i].tolist())\n",
    "#     #print(start_date.month,' ',start_date.day,' ',start_date.hour,' ',start_date.weekday(),' ',start_date.timetuple().tm_yday,' ',start_date.isocalendar()[1])\n",
    "#     start_date=start_date+ timedelta(hours=1)\n",
    "#     #print('year',start_date.year,'Month:',start_date.month,' day:',start_date.day,' hour:',start_date.hour)\n",
    "#     Data.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b2dab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len x_batches (25921, 24, 11)  len y_batches (25921, 24, 1)\n",
      "len x_testbatches (7, 24, 11)  len y_testbatches (7, 24, 1)\n",
      "Finished processing time series 1 of 1\n"
     ]
    }
   ],
   "source": [
    "x_batches_Full = []\n",
    "y_batches_Full = []\n",
    "X_Test_Full = []\n",
    "Y_Test_Full = []\n",
    "###################################################\n",
    "for i in range(0, len(data)):\n",
    "    x_batches = []\n",
    "    y_batches = []\n",
    "    X_Test = []\n",
    "    Y_Test = []\n",
    "    TimeSeries = data.iloc[i, :]\n",
    "    x_batches, y_batches, X_Test, Y_Test = New_preprocessing(TimeSeries)\n",
    "    for element1 in x_batches:\n",
    "        x_batches_Full.append(element1)\n",
    "\n",
    "    for element2 in y_batches:\n",
    "        y_batches_Full.append(element2)\n",
    "\n",
    "    for element5 in X_Test:\n",
    "        X_Test_Full.append(element5)\n",
    "\n",
    "    for element6 in Y_Test:\n",
    "        Y_Test_Full.append(element6)\n",
    "    print(\"Finished processing time series\", i + 1, \"of\", len(data))\n",
    "\n",
    "# ---------------------shuffle windows  X and target Y together-------------------------------------\n",
    "combined = list(zip(x_batches_Full, y_batches_Full))\n",
    "random.shuffle(combined)\n",
    "shuffled_batch_features, shuffled_batch_y = zip(*combined)\n",
    "\n",
    "# xgboost part\n",
    "All_Training_Instances = []\n",
    "\n",
    "# =============== flatten each training window into Instance =================================\n",
    "for i in range(0, len(shuffled_batch_features)):\n",
    "    hold = []\n",
    "    temp = []\n",
    "    for j in range(0, len(shuffled_batch_features[i])):\n",
    "        # **************** to run without features -->comment if else condition (just keep else statement) **************************\n",
    "        # Fixed\n",
    "        #   if include_features or include_motif_information:\n",
    "        #       if j==(len(shuffled_batch_features[i])-1):\n",
    "        #             hold=np.concatenate((hold, shuffled_batch_features[i][j][:]), axis=None)\n",
    "        #       else:\n",
    "        #         hold=np.concatenate((hold, shuffled_batch_features[i][j][0]), axis=None)\n",
    "        #   else:\n",
    "        #       hold=np.concatenate((hold, shuffled_batch_features[i][j][0]), axis=None)\n",
    "        if j == (len(shuffled_batch_features[i]) - 1):\n",
    "            hold = np.concatenate((hold, shuffled_batch_features[i][j][:]), axis=None)\n",
    "        else:\n",
    "            hold = np.concatenate((hold, shuffled_batch_features[i][j][0]), axis=None)\n",
    "        # hold=np.concatenate((hold, shuffled_batch_features[i][j][:]), axis=None)\n",
    "    All_Training_Instances.append(hold)\n",
    "\n",
    "\n",
    "# print(len(All_Training_Instances[0]))\n",
    "\n",
    "# =============== flatten each testing window into Instance =================================\n",
    "All_Testing_Instances = []\n",
    "for i in range(0, len(X_Test_Full)):\n",
    "    hold = []\n",
    "    temp = []\n",
    "    for j in range(0, len(X_Test_Full[i])):\n",
    "        # **************** to run without features -->comment if else condition (just keep else statement) **************************\n",
    "        # Fixed\n",
    "        #   if include_features or include_motif_information:\n",
    "        #       if j==(len(X_Test_Full[i])-1):\n",
    "        #           hold=np.concatenate((hold, X_Test_Full[i][j][:]), axis=None)\n",
    "        #       else:\n",
    "        #           hold=np.concatenate((hold, X_Test_Full[i][j][0]), axis=None)\n",
    "        #   else:\n",
    "        #       hold=np.concatenate((hold, X_Test_Full[i][j][0]), axis=None)\n",
    "        if j == (len(X_Test_Full[i]) - 1):\n",
    "            hold = np.concatenate((hold, X_Test_Full[i][j][:]), axis=None)\n",
    "        else:\n",
    "            hold = np.concatenate((hold, X_Test_Full[i][j][0]), axis=None)\n",
    "        # hold=np.concatenate((hold, X_Test_Full[i][j][:]), axis=None)\n",
    "    All_Testing_Instances.append(hold)\n",
    "\n",
    "# print(len(All_Testing_Instances[0]))\n",
    "\n",
    "# =========================== final shape check =========================\n",
    "All_Testing_Instances = np.reshape(\n",
    "    All_Testing_Instances, (len(All_Testing_Instances), len(All_Testing_Instances[0]))\n",
    ")\n",
    "Y_Test_Full = np.reshape(Y_Test_Full, (len(Y_Test_Full), num_periods_output))\n",
    "\n",
    "All_Training_Instances = np.reshape(\n",
    "    All_Training_Instances,\n",
    "    (len(All_Training_Instances), len(All_Training_Instances[0])),\n",
    ")\n",
    "shuffled_batch_y = np.reshape(\n",
    "    shuffled_batch_y, (len(shuffled_batch_y), num_periods_output)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dde6bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All_Testing_Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aecc00",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccb024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================== CALLING XGBOOST ===========================\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.2,\n",
    "    n_estimators=150,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=1,\n",
    "    # seed=42,silent=False\n",
    "    random_state=42,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "multioutput = MultiOutputRegressor(\n",
    "    model, n_jobs=1  # ensures sequential fitting, avoids nondeterminism in threading\n",
    ").fit(All_Training_Instances, shuffled_batch_y)\n",
    "\n",
    "\n",
    "print(\"Fitting Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bab13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_Testing_Instances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6be125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== PREDICTION ===============================\n",
    "prediction = multioutput.predict(All_Testing_Instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3ad375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction, Y_Test_Full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73859052",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e354342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  141.68057\n",
      "WAPE:  0.09365346\n",
      "MAE:  52.456245\n"
     ]
    }
   ],
   "source": [
    "print_prediction_results(prediction, Y_Test_Full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd1027",
   "metadata": {},
   "source": [
    "# Results\n",
    "- test\n",
    "```\n",
    "RMSE:  161.62082\n",
    "WAPE:  0.10943094\n",
    "MAE:  61.293365\n",
    "\n",
    "t =10\n",
    "RMSE:  67.59057\n",
    "WAPE:  0.100073926\n",
    "MAE:  36.478226\n",
    "\n",
    "without \n",
    "RMSE:  68.286255\n",
    "WAPE:  0.100807734\n",
    "MAE:  36.74571\n",
    "\n",
    "\n",
    "RMSE:  139.36037\n",
    "WAPE:  0.10478689\n",
    "MAE:  58.69219\n",
    "\n",
    "no delta + no dist\n",
    "RMSE:  5.4564867\n",
    "WAPE:  0.07584218\n",
    "MAE:  3.7579868\n",
    "\n",
    "no delta\n",
    "RMSE:  5.4955373\n",
    "WAPE:  0.078908354\n",
    "MAE:  3.9099162\n",
    "\n",
    "Wih all\n",
    "RMSE:  5.7024674\n",
    "WAPE:  0.07927269\n",
    "MAE:  3.9279687\n",
    " \n",
    "With feature\n",
    "RMSE:  4.746327\n",
    "WAPE:  0.06622907\n",
    "MAE:  3.2816563\n",
    "\n",
    "With out feature\n",
    "RMSE:  5.7828765\n",
    "WAPE:  0.080296926\n",
    "MAE:  3.9787197\n",
    "```\n",
    "- top-k motif family\n",
    "- top-k motif\n",
    "- top-1 motif\n",
    "```\n",
    "With Original Features + With Motif Information (top-1, l=5)\n",
    "\n",
    "Without Original Features + With Motif Information (top-1, l=5)\n",
    "\n",
    "With Original Features + With Motif Information (top-1, l=2)\n",
    "\n",
    "Without Original Features + With Motif Information (top-1, l=2)\n",
    "\n",
    "With Original Features + With Motif Information (top-1, l=1)\n",
    "Witha all\n",
    "RMSE:  155.0223\n",
    "WAPE:  0.10833517\n",
    "MAE:  60.67961\n",
    "\n",
    "Without Original Features + With Motif Information (top-1, l=1)\n",
    "```\n",
    "- Original\n",
    "```\n",
    "With Original Features\n",
    "RMSE:  132.66907\n",
    "WAPE:  0.09288037\n",
    "MAE:  52.023224\n",
    "\n",
    "Without Original Features\n",
    "RMSE:  136.25429\n",
    "WAPE:  0.10342441\n",
    "MAE:  57.92905\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39dde74",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpmf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
