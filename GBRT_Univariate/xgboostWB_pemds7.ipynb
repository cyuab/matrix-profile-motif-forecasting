{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748cbbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n",
      "Fitting Done!\n",
      "RMSE:  5.190582\n",
      "WAPE:  0.04798727\n",
      "MAE:  2.7961516\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"XGBoostWB_PeMDS7\"\"\"\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.version\n",
    "# Import Libraries\n",
    "# import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# %matplotlib inline\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "from random import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "\n",
    "num_periods_output = 9  # to predict\n",
    "num_periods_input = 9  # input\n",
    "\n",
    "ALL_Test_Data = []\n",
    "ALL_Test_Prediction = []\n",
    "\n",
    "\"\"\"## preprocessing\"\"\"\n",
    "\n",
    "\n",
    "def New_preprocessing(TimeSeries):\n",
    "    # print(len(TimeSeries))\n",
    "    Data = []\n",
    "    start_date = datetime(2012, 5, 1, 00, 00, 00)  # define start date\n",
    "    for i in range(0, len(TimeSeries)):\n",
    "        record = []\n",
    "        record.append(TimeSeries[i])  # adding the pemds7 value\n",
    "        record.append(start_date.month)\n",
    "        record.append(start_date.day)\n",
    "        record.append(start_date.hour)\n",
    "        record.append(start_date.minute)\n",
    "        record.append(start_date.weekday())\n",
    "        record.append(start_date.timetuple().tm_yday)\n",
    "        record.append(start_date.isocalendar()[1])\n",
    "        # print(start_date.month,' ',start_date.day,' ',start_date.hour,' ',start_date.weekday(),' ',start_date.timetuple().tm_yday,' ',start_date.isocalendar()[1])\n",
    "        start_date = start_date + timedelta(minutes=5)\n",
    "        # print('year',start_date.year,'Month:',start_date.month,' day:',start_date.day,' hour:',start_date.hour)\n",
    "        Data.append(record)\n",
    "    ########## change list of lists to df ################\n",
    "    headers = [\n",
    "        \"pems\",\n",
    "        \"month\",\n",
    "        \"day\",\n",
    "        \"hour\",\n",
    "        \"minute\",\n",
    "        \"day_of_week\",\n",
    "        \"day_of_year\",\n",
    "        \"week_of_year\",\n",
    "    ]\n",
    "    Data_df = pd.DataFrame(Data, columns=headers)\n",
    "    sub = Data_df.iloc[:, 1:]\n",
    "    # Normalize features to be from -0.5 to 0.5 as mentioned in the paper\n",
    "    New_sub = preprocessing.minmax_scale(sub, feature_range=(-0.5, 0.5))\n",
    "    Normalized_Data_df = pd.DataFrame(\n",
    "        np.column_stack([Data_df.iloc[:, 0], New_sub]), columns=headers\n",
    "    )\n",
    "    # print(Normalized_Data_df)\n",
    "    #################################################################################################\n",
    "    # cut training and testing training is 11232\n",
    "    Train = Normalized_Data_df.iloc[0:11232, :]\n",
    "    Train = Train.values\n",
    "    Train = Train.astype(\"float32\")\n",
    "    # print('Traing length :',len(Train))\n",
    "    Test = Normalized_Data_df.iloc[(11232 - num_periods_input) :, :]\n",
    "    Test = Test.values\n",
    "    Test = Test.astype(\"float32\")\n",
    "    # print('Traing length :',len(Test))\n",
    "    Number_Of_Features = 8\n",
    "    ############################################ Windowing ##################################\n",
    "    end = len(Train)\n",
    "    start = 0\n",
    "    next = 0\n",
    "    x_batches = []\n",
    "    y_batches = []\n",
    "    count = 0\n",
    "    while next + (num_periods_input + num_periods_output) < end:\n",
    "        next = start + num_periods_input\n",
    "        x_batches.append(Train[start:next, :])\n",
    "        y_batches.append(Train[next : next + num_periods_output, 0])\n",
    "        start = start + 1\n",
    "    y_batches = np.asarray(y_batches)\n",
    "    y_batches = y_batches.reshape(-1, num_periods_output, 1)\n",
    "    # print('Length of y batches :',len(y_batches),' ',num_periods_input,' ',num_periods_output)\n",
    "    # print(x_batches)\n",
    "    x_batches = np.asarray(x_batches)\n",
    "    x_batches = x_batches.reshape(-1, num_periods_input, Number_Of_Features)\n",
    "    # print('len x_batches ',len(x_batches))\n",
    "    ############################################ Windowing ##################################\n",
    "    end_test = len(Test)\n",
    "    start_test = 0\n",
    "    next_test = 0\n",
    "    x_testbatches = []\n",
    "    y_testbatches = []\n",
    "    # print('lennnn',len(Train))\n",
    "    while next_test + (num_periods_input + num_periods_output) < end_test:\n",
    "        next_test = start_test + num_periods_input\n",
    "        x_testbatches.append(Test[start_test:next_test, :])\n",
    "        y_testbatches.append(Test[next_test : next_test + num_periods_output, 0])\n",
    "        start_test = start_test + 1\n",
    "    y_testbatches = np.asarray(y_testbatches)\n",
    "    y_testbatches = y_testbatches.reshape(-1, num_periods_output, 1)\n",
    "    x_testbatches = np.asarray(x_testbatches)\n",
    "    x_testbatches = x_testbatches.reshape(-1, num_periods_input, Number_Of_Features)\n",
    "    # print('len Test',len(Test))\n",
    "    # print('len xTestbatches',len(x_testbatches))\n",
    "    return x_batches, y_batches, x_testbatches, y_testbatches\n",
    "\n",
    "data_path = r\"../data/pems.npy\"\n",
    "\n",
    "data = np.load(data_path)\n",
    "data = pd.DataFrame(data)\n",
    "# print('Number of timeseries: ',len(data))\n",
    "x_batches_Full = []\n",
    "y_batches_Full = []\n",
    "X_Test_Full = []\n",
    "Y_Test_Full = []\n",
    "for i in range(0, len(data)):\n",
    "    x_batches = []\n",
    "    y_batches = []\n",
    "    X_Test = []\n",
    "    Y_Test = []\n",
    "    TimeSeries = data.iloc[i, :]\n",
    "    x_batches, y_batches, X_Test, Y_Test = New_preprocessing(TimeSeries)\n",
    "    for element1 in x_batches:\n",
    "        x_batches_Full.append(element1)\n",
    "\n",
    "    for element2 in y_batches:\n",
    "        y_batches_Full.append(element2)\n",
    "\n",
    "    for element5 in X_Test:\n",
    "        X_Test_Full.append(element5)\n",
    "\n",
    "    for element6 in Y_Test:\n",
    "        Y_Test_Full.append(element6)\n",
    "\n",
    "# ---------------------shuffle windows  X and target Y together-------------------------------------\n",
    "# print(len(x_batches_Full),'     length of all file : ',len(y_batches_Full))\n",
    "combined = list(zip(x_batches_Full, y_batches_Full))\n",
    "random.shuffle(combined)\n",
    "shuffled_batch_features, shuffled_batch_y = zip(*combined)\n",
    "\n",
    "# xgboost part\n",
    "All_Training_Instances = []\n",
    "\n",
    "# =============== flatten each training window into Instance =================================\n",
    "for i in range(0, len(shuffled_batch_features)):\n",
    "    hold = []\n",
    "    temp = []\n",
    "    for j in range(0, len(shuffled_batch_features[i])):\n",
    "        # **************** to run without features -->comment if else condition (just keep else statement) **************************\n",
    "        if j == (len(shuffled_batch_features[i]) - 1):\n",
    "            hold = np.concatenate((hold, shuffled_batch_features[i][j][:]), axis=None)\n",
    "            # hold = np.concatenate((hold, shuffled_batch_features[i][j][0]), axis=None)\n",
    "        else:\n",
    "            hold = np.concatenate((hold, shuffled_batch_features[i][j][0]), axis=None)\n",
    "\n",
    "    All_Training_Instances.append(hold)\n",
    "\n",
    "\n",
    "print(len(All_Training_Instances[0]))\n",
    "\n",
    "\n",
    "# =============== flatten each testing window into Instance =================================\n",
    "All_Testing_Instances = []\n",
    "for i in range(0, len(X_Test_Full)):\n",
    "    hold = []\n",
    "    temp = []\n",
    "    for j in range(0, len(X_Test_Full[i])):\n",
    "        # **************** to run without features -->comment if else condition (just keep else statement) **************************\n",
    "        if j == (len(X_Test_Full[i]) - 1):\n",
    "            hold = np.concatenate((hold, X_Test_Full[i][j][:]), axis=None)\n",
    "            # hold = np.concatenate((hold, X_Test_Full[i][j][0]), axis=None)\n",
    "        else:\n",
    "            hold = np.concatenate((hold, X_Test_Full[i][j][0]), axis=None)\n",
    "\n",
    "    All_Testing_Instances.append(hold)\n",
    "\n",
    "print(len(All_Testing_Instances[0]))\n",
    "\n",
    "# =========================== final shape check =========================\n",
    "All_Testing_Instances = np.reshape(\n",
    "    All_Testing_Instances, (len(All_Testing_Instances), len(All_Testing_Instances[0]))\n",
    ")\n",
    "Y_Test_Full = np.reshape(Y_Test_Full, (len(Y_Test_Full), num_periods_output))\n",
    "\n",
    "All_Training_Instances = np.reshape(\n",
    "    All_Training_Instances,\n",
    "    (len(All_Training_Instances), len(All_Training_Instances[0])),\n",
    ")\n",
    "shuffled_batch_y = np.reshape(\n",
    "    shuffled_batch_y, (len(shuffled_batch_y), num_periods_output)\n",
    ")\n",
    "\n",
    "\n",
    "# =========================== CALLING XGBOOST ===========================\n",
    "model = xgb.XGBRegressor(\n",
    "    learning_rate=0.045,\n",
    "    n_estimators=150,\n",
    "    max_depth=8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=1,\n",
    "    random_state=42,\n",
    "    verbosity=1,\n",
    ")\n",
    "\n",
    "multioutput = MultiOutputRegressor(model).fit(All_Training_Instances, shuffled_batch_y)\n",
    "\n",
    "print(\"Fitting Done!\")\n",
    "\n",
    "# ============================== PREDICTION ===============================\n",
    "prediction = multioutput.predict(All_Testing_Instances)\n",
    "# print('prediction ',prediction.shape)\n",
    "# print('test ',Y_Test_Full.shape)\n",
    "MSE = np.mean((prediction - Y_Test_Full) ** 2)\n",
    "MAE = np.mean(np.abs((prediction - Y_Test_Full)))\n",
    "MAPE = np.mean((np.abs(prediction - Y_Test_Full) / np.abs(Y_Test_Full)))\n",
    "WAPE = np.sum(np.abs(prediction - Y_Test_Full)) / np.sum(np.abs(Y_Test_Full))\n",
    "# print('With Features for {} weeks'.format(No_Of_weeks))\n",
    "# print('With Features for {} weeks'.format(No_Of_weeks))\n",
    "print(\"RMSE: \", MSE**0.5)\n",
    "print(\"WAPE: \", WAPE)\n",
    "print(\"MAE: \", MAE)\n",
    "# print(\"MAPE: \", MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without covariates\n",
    "# RMSE:  5.6098986\n",
    "# WAPE:  0.05121678\n",
    "# MAE:  2.984331\n",
    "\n",
    "# With time-covariates\n",
    "# RMSE:  5.190582\n",
    "# WAPE:  0.04798727\n",
    "# MAE:  2.7961516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7896a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was last run end-to-end on: 2026-01-08 20:40:25.481493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "print(f\"This notebook was last run end-to-end on: {datetime.datetime.now()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpmf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
